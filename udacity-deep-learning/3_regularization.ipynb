{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  beta_regul = tf.placeholder(tf.float32)\n",
    "  \n",
    "  # Variables.\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels)) + beta_regul * tf.nn.l2_loss(weights)\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 18.687693\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 18.1%\n",
      "Minibatch loss at step 500: 2.275040\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 1000: 1.597625\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 1500: 0.947071\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 2000: 0.833254\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2500: 0.821301\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 3000: 0.758426\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.8%\n",
      "Test accuracy: 89.0%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 1e-3}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_steps = 3001\n",
    "regul_val = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_val = []\n",
    "\n",
    "for regul in regul_val:\n",
    "  with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "      offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "      batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "      batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "      feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : regul}\n",
    "      _, l, predictions = session.run(\n",
    "        [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    accuracy_val.append(accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAF4CAYAAAAWmIDXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAKA7BQMA6E7BAAC6UzAAgO4UDACgu1/KWlUvoGh46QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x245e9dca978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(regul_val, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.title('Test accuracy by regularization (logistic)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Hidden Layer NN L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  beta_regul = tf.placeholder(tf.float32)\n",
    "  \n",
    "  # Variables.\n",
    "  weights1 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "  biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  weights2 = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "  biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "  logits = tf.matmul(lay1_train, weights2) + biases2\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels)) + \\\n",
    "      beta_regul * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "  lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(lay1_test, weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 634.622498\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 21.8%\n",
      "Minibatch loss at step 500: 197.669678\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1000: 116.977318\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1500: 68.100464\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 2000: 41.386410\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 2500: 25.158102\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 3000: 15.479199\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 86.3%\n",
      "Test accuracy: 92.9%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 1e-3}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_steps = 3001\n",
    "regul_val = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_val = []\n",
    "\n",
    "for regul in regul_val:    \n",
    "  with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for step in range(num_steps):\n",
    "      # Pick an offset within the training data, which has been randomized.\n",
    "      # Note: we could use better randomization across epochs.\n",
    "      offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "      # Generate a minibatch.\n",
    "      batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "      batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "      # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "      # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "      # and the value is the numpy array to feed to it.\n",
    "      feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : regul}\n",
    "      _, l, predictions = session.run(\n",
    "        [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    accuracy_val.append(accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAF4CAYAAAAWmIDXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2461ed2f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(regul_val, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.title('Test accuracy by regularization (1-layer net)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  beta_regul = tf.placeholder(tf.float32)\n",
    "  \n",
    "  # Variables.\n",
    "  weights1 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "  biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  weights2 = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "  biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "  logits = tf.matmul(lay1_train, weights2) + biases2\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels)) + \\\n",
    "      beta_regul * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "  lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(lay1_test, weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 747.627686\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 14.6%\n",
      "Minibatch loss at step 10: 376.154144\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 31.3%\n",
      "Minibatch loss at step 20: 339.368378\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 35.1%\n",
      "Minibatch loss at step 30: 335.990662\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 35.1%\n",
      "Minibatch loss at step 40: 332.646729\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 35.1%\n",
      "Minibatch loss at step 50: 329.336121\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 35.1%\n",
      "Minibatch loss at step 60: 326.058289\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 35.1%\n",
      "Minibatch loss at step 70: 322.813171\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 35.1%\n",
      "Minibatch loss at step 80: 319.600372\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 35.1%\n",
      "Minibatch loss at step 90: 316.419403\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 35.1%\n",
      "Minibatch loss at step 100: 313.270294\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 35.1%\n",
      "Test accuracy: 37.4%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 101\n",
    "num_batches = 3\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step % num_batches * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 1e-3}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 10 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-Layer NN L2 Dropout 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  beta_regul = tf.placeholder(tf.float32)\n",
    "  \n",
    "  # Variables.\n",
    "  weights1 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "  biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  weights2 = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "  biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "  drop1 = tf.nn.dropout(lay1_train, 0.5)\n",
    "  logits = tf.matmul(drop1, weights2) + biases2\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels)) + \\\n",
    "      beta_regul * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "  lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(lay1_test, weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 776.933289\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 26.0%\n",
      "Minibatch loss at step 500: 207.045807\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 1000: 119.534645\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1500: 69.734932\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2000: 41.937271\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 83.8%\n",
      "Minibatch loss at step 2500: 25.340933\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 3000: 15.516317\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.2%\n",
      "Test accuracy: 91.9%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 1e-3}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes1 = 1024\n",
    "num_hidden_nodes2 = 256\n",
    "num_hidden_nodes3 = 128\n",
    "keep_prob = 0.5\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  global_step = tf.Variable(0)\n",
    "\n",
    "  # Variables.\n",
    "  weights1 = tf.Variable(\n",
    "    tf.truncated_normal(\n",
    "        [image_size * image_size, num_hidden_nodes1],\n",
    "        stddev=np.sqrt(2.0 / (image_size * image_size)))\n",
    "    )\n",
    "  biases1 = tf.Variable(tf.zeros([num_hidden_nodes1]))\n",
    "  weights2 = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes1, num_hidden_nodes2], stddev=np.sqrt(2.0 / num_hidden_nodes1)))\n",
    "  biases2 = tf.Variable(tf.zeros([num_hidden_nodes2]))\n",
    "  weights3 = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes2, num_hidden_nodes3], stddev=np.sqrt(2.0 / num_hidden_nodes2)))\n",
    "  biases3 = tf.Variable(tf.zeros([num_hidden_nodes3]))\n",
    "  weights4 = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes3, num_labels], stddev=np.sqrt(2.0 / num_hidden_nodes3)))\n",
    "  biases4 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "  drop1 = tf.nn.dropout(lay1_train, 0.5)\n",
    "  lay2_train = tf.nn.relu(tf.matmul(drop1, weights2) + biases2)\n",
    "  drop2 = tf.nn.dropout(lay2_train, 0.5)\n",
    "  lay3_train = tf.nn.relu(tf.matmul(drop2, weights3) + biases3)\n",
    "  drop3 = tf.nn.dropout(lay3_train, 0.5)\n",
    "  logits = tf.matmul(drop3, weights4) + biases4\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "  \n",
    "  # Optimizer.\n",
    "  learning_rate = tf.train.exponential_decay(0.5, global_step, 4000, 0.65, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "  lay2_valid = tf.nn.relu(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "  lay3_valid = tf.nn.relu(tf.matmul(lay2_valid, weights3) + biases3)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(lay3_valid, weights4) + biases4)\n",
    "  lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "  lay2_test = tf.nn.relu(tf.matmul(lay1_test, weights2) + biases2)\n",
    "  lay3_test = tf.nn.relu(tf.matmul(lay2_test, weights3) + biases3)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(lay3_test, weights4) + biases4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.744393\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 20.6%\n",
      "Minibatch loss at step 500: 0.469030\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 83.7%\n",
      "Minibatch loss at step 1000: 0.696148\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 84.3%\n",
      "Minibatch loss at step 1500: 0.449932\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 2000: 0.418703\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 2500: 0.492413\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 3000: 0.549425\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 3500: 0.574398\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 4000: 0.373831\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 4500: 0.472405\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 5000: 0.507178\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 5500: 0.479149\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 6000: 0.526199\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 6500: 0.338149\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 7000: 0.505005\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 7500: 0.514125\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 8000: 0.648089\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 8500: 0.389314\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 9000: 0.361019\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 9500: 0.446574\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 10000: 0.437215\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 10500: 0.310235\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 11000: 0.292794\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 11500: 0.390373\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 12000: 0.628732\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 12500: 0.318034\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 13000: 0.430505\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 13500: 0.455600\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 14000: 0.559983\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 14500: 0.534483\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 15000: 0.356852\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 15500: 0.508225\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 16000: 0.262162\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 16500: 0.279352\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 17000: 0.245483\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 17500: 0.159812\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 18000: 0.258309\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 89.7%\n",
      "Test accuracy: 95.5%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 18001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
